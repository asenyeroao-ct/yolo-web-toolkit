"""
YOLO æ¨¡å‹è¨“ç·´æ¨¡å¡Š

æ­¤æ¨¡å¡Šæä¾›ä½¿ç”¨ Ultralytics YOLO è¨“ç·´æ¨¡å‹çš„åŠŸèƒ½ã€‚
æ•´åˆäº†æ™ºèƒ½æ•¸æ“šé›†æ¸…ç†ã€æ¢é‡è¨“ç·´ã€è‡ªå‹•è¶…åƒæ•¸èª¿æ•´ç­‰å„ªåŒ–ç­–ç•¥ã€‚
"""

import os
import sys
import random
import shutil
import subprocess
from pathlib import Path
from typing import Optional, Tuple, Dict

try:
    from ultralytics import YOLO
    import torch
    import pandas as pd
    from PIL import Image, ImageFile
    ImageFile.LOAD_TRUNCATED_IMAGES = True
except ImportError as e:
    raise ImportError(
        "éœ€è¦å®‰è£å¿…è¦çš„ä¾è³´ã€‚è«‹ç¢ºä¿å·²å®‰è£:\n"
        "  - ultralytics\n"
        "  - torch\n"
        "  - pandas\n"
        "  - Pillow\n"
        f"åŸå§‹éŒ¯èª¤: {e}"
    )


# ================= æ•¸æ“šé›†å„ªåŒ–åŠŸèƒ½ =================

def remove_bad_images(train_images_folder: str, train_labels_folder: str, 
                      min_w: int = 14, min_h: int = 24, verbose: bool = True) -> int:
    """
    ç§»é™¤åŒ…å«éå°æ¡†çš„åœ–åƒï¼ˆä¿ç•™èƒŒæ™¯åœ–åƒï¼‰
    
    Args:
        train_images_folder: è¨“ç·´åœ–åƒè³‡æ–™å¤¾
        train_labels_folder: è¨“ç·´æ¨™ç±¤è³‡æ–™å¤¾
        min_w: æœ€å°å¯¬åº¦ï¼ˆåƒç´ ï¼‰
        min_h: æœ€å°é«˜åº¦ï¼ˆåƒç´ ï¼‰
        verbose: æ˜¯å¦è¼¸å‡ºè©³ç´°ä¿¡æ¯
        
    Returns:
        ç§»é™¤çš„åœ–åƒæ•¸é‡
    """
    removed = 0
    if not os.path.exists(train_labels_folder):
        return removed
    
    for lbl_file in os.listdir(train_labels_folder):
        if not lbl_file.endswith('.txt'):
            continue
            
        lbl_path = os.path.join(train_labels_folder, lbl_file)
        img_path = os.path.join(train_images_folder, lbl_file.replace('.txt', '.jpg'))
        
        # å¦‚æœåœ–åƒä¸å­˜åœ¨ï¼Œå˜—è©¦å…¶ä»–æ ¼å¼
        if not os.path.exists(img_path):
            for ext in ['.png', '.jpeg', '.JPG', '.PNG']:
                alt_path = os.path.join(train_images_folder, lbl_file.replace('.txt', ext))
                if os.path.exists(alt_path):
                    img_path = alt_path
                    break
        
        if not os.path.exists(img_path):
            continue
        
        try:
            with open(lbl_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            # ä¿ç•™èƒŒæ™¯åœ–åƒï¼ˆç„¡æ¨™ç±¤ï¼‰
            if len(lines) == 0:
                continue
            
            # è®€å–åœ–åƒå°ºå¯¸
            with Image.open(img_path) as im:
                W, H = im.size
            
            # æª¢æŸ¥æ˜¯å¦æœ‰éå°çš„æ¡†
            should_remove = False
            for line in lines:
                parts = line.strip().split()
                if len(parts) < 5:
                    continue
                try:
                    _, x, y, w, h = map(float, parts[:5])
                    if w * W < min_w or h * H < min_h:
                        should_remove = True
                        break
                except (ValueError, IndexError):
                    continue
            
            if should_remove:
                try:
                    os.remove(lbl_path)
                    os.remove(img_path)
                    removed += 1
                except Exception:
                    pass
        except Exception:
            continue
    
    if verbose and removed > 0:
        print(f"ğŸ—‘ï¸ ç§»é™¤äº† {removed} å¼µåŒ…å«éå°æ¡†çš„åœ–åƒï¼ˆèƒŒæ™¯åœ–åƒå·²ä¿ç•™ï¼‰")
    
    return removed


def cap_instances(train_labels_folder: str, max_inst: int = 6, verbose: bool = True) -> int:
    """
    é™åˆ¶æ¯å¼µåœ–åƒçš„æœ€å¤§å¯¦ä¾‹æ•¸é‡
    
    Args:
        train_labels_folder: è¨“ç·´æ¨™ç±¤è³‡æ–™å¤¾
        max_inst: æœ€å¤§å¯¦ä¾‹æ•¸é‡
        verbose: æ˜¯å¦è¼¸å‡ºè©³ç´°ä¿¡æ¯
        
    Returns:
        è¢«é™åˆ¶çš„æ¨™ç±¤æ–‡ä»¶æ•¸é‡
    """
    capped = 0
    if not os.path.exists(train_labels_folder):
        return capped
    
    for lbl_file in os.listdir(train_labels_folder):
        if not lbl_file.endswith('.txt'):
            continue
        
        lbl_path = os.path.join(train_labels_folder, lbl_file)
        try:
            with open(lbl_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            if len(lines) > max_inst:
                random.shuffle(lines)
                with open(lbl_path, 'w', encoding='utf-8') as f:
                    f.writelines(lines[:max_inst])
                capped += 1
        except Exception:
            continue
    
    if verbose and capped > 0:
        print(f"ğŸ“Š é™åˆ¶äº† {capped} å€‹æ¨™ç±¤æ–‡ä»¶çš„å¯¦ä¾‹æ•¸é‡ï¼ˆæœ€å¤š {max_inst} å€‹ï¼‰")
    
    return capped


def create_validation_set(train_images_folder: str, train_labels_folder: str,
                          val_images_folder: str, val_labels_folder: str,
                          val_split: float = 0.15, bg_val_ratio: float = 0.08,
                          verbose: bool = True) -> Tuple[int, int]:
    """
    æ™ºèƒ½å‰µå»ºé©—è­‰é›†ï¼ˆå€åˆ†å¤šå¯¦ä¾‹ã€å–®å¯¦ä¾‹å’ŒèƒŒæ™¯åœ–åƒï¼‰
    
    Args:
        train_images_folder: è¨“ç·´åœ–åƒè³‡æ–™å¤¾
        train_labels_folder: è¨“ç·´æ¨™ç±¤è³‡æ–™å¤¾
        val_images_folder: é©—è­‰åœ–åƒè³‡æ–™å¤¾
        val_labels_folder: é©—è­‰æ¨™ç±¤è³‡æ–™å¤¾
        val_split: é©—è­‰é›†æ¯”ä¾‹
        bg_val_ratio: èƒŒæ™¯åœ–åƒåœ¨é©—è­‰é›†ä¸­çš„æ¯”ä¾‹
        verbose: æ˜¯å¦è¼¸å‡ºè©³ç´°ä¿¡æ¯
        
    Returns:
        (é©—è­‰é›†åœ–åƒæ•¸é‡, èƒŒæ™¯åœ–åƒæ•¸é‡) å…ƒçµ„
    """
    os.makedirs(val_images_folder, exist_ok=True)
    os.makedirs(val_labels_folder, exist_ok=True)
    
    # å¦‚æœé©—è­‰é›†å·²å­˜åœ¨ä¸”ä¸ç‚ºç©ºï¼Œè·³éå‰µå»º
    if os.path.exists(val_labels_folder) and len(os.listdir(val_labels_folder)) > 0:
        if verbose:
            print(f"ğŸ“‚ é©—è­‰é›†å·²å­˜åœ¨ï¼Œè·³éå‰µå»º")
        return len(os.listdir(val_labels_folder)), 0
    
    multi, single, bg = [], [], []
    
    if not os.path.exists(train_labels_folder):
        return 0, 0
    
    for lbl_file in os.listdir(train_labels_folder):
        if not lbl_file.endswith('.txt'):
            continue
        
        lbl_path = os.path.join(train_labels_folder, lbl_file)
        try:
            with open(lbl_path, 'r', encoding='utf-8') as f:
                n = len([line for line in f if line.strip()])
            
            img_file = lbl_file.replace('.txt', '.jpg')
            img_path = os.path.join(train_images_folder, img_file)
            if not os.path.exists(img_path):
                for ext in ['.png', '.jpeg', '.JPG', '.PNG']:
                    alt_path = os.path.join(train_images_folder, lbl_file.replace('.txt', ext))
                    if os.path.exists(alt_path):
                        img_file = lbl_file.replace('.txt', ext)
                        img_path = alt_path
                        break
                if not os.path.exists(img_path):
                    continue
            
            if n >= 2:
                multi.append((lbl_file, img_file))
            elif n == 1:
                single.append((lbl_file, img_file))
            else:
                bg.append((lbl_file, img_file))
        except Exception:
            continue
    
    total_train = len(multi) + len(single) + len(bg)
    if total_train == 0:
        return 0, 0
    
    total_val = max(1, int(total_train * val_split))
    bg_target = max(1, int(total_val * bg_val_ratio))
    non_bg_target = total_val - bg_target
    
    chosen = []
    chosen.extend(bg[:bg_target])
    chosen.extend((multi + single)[:non_bg_target])
    chosen = chosen[:total_val]
    
    moved = 0
    for lbl_file, img_file in chosen:
        try:
            src_lbl = os.path.join(train_labels_folder, lbl_file)
            src_img = os.path.join(train_images_folder, img_file)
            dst_lbl = os.path.join(val_labels_folder, lbl_file)
            dst_img = os.path.join(val_images_folder, img_file)
            
            if os.path.exists(src_lbl):
                shutil.move(src_lbl, dst_lbl)
            if os.path.exists(src_img):
                shutil.move(src_img, dst_img)
            moved += 1
        except Exception:
            continue
    
    if verbose:
        print(f"ğŸ“‚ å‰µå»ºé©—è­‰é›†: {moved} å¼µåœ–åƒ | {bg_target} å¼µèƒŒæ™¯åœ–åƒ")
    
    return moved, bg_target


def calculate_dataset_stats(train_images_folder: str, train_labels_folder: str) -> Dict:
    """
    è¨ˆç®—æ•¸æ“šé›†çµ±è¨ˆä¿¡æ¯
    
    Returns:
        åŒ…å«åœ–åƒæ•¸é‡ã€å¯¦ä¾‹æ•¸é‡ã€å¯†åº¦çš„å­—å…¸
    """
    if not os.path.exists(train_images_folder) or not os.path.exists(train_labels_folder):
        return {'num_imgs': 0, 'instances': 0, 'density': 0.0}
    
    num_imgs = len([f for f in os.listdir(train_images_folder) 
                   if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
    
    instances = 0
    for lbl_file in os.listdir(train_labels_folder):
        if not lbl_file.endswith('.txt'):
            continue
        try:
            with open(os.path.join(train_labels_folder, lbl_file), 'r', encoding='utf-8') as f:
                instances += len([line for line in f if line.strip()])
        except Exception:
            continue
    
    density = instances / max(1, num_imgs)
    
    return {
        'num_imgs': num_imgs,
        'instances': instances,
        'density': density
    }


def train_yolo_model(
    yolo_version: str = 'yolo12',
    model_size: str = 'n',
    images_folder: str = '',
    labels_folder: str = '',
    output_destination: str = '',
    epochs: int = 100,
    batch_size: int = 16,
    imgsz: int = 640,
    resume: bool = False,
    verbose: bool = True,
    # å„ªåŒ–é¸é …
    enable_optimization: bool = False,
    min_w: int = 14,
    min_h: int = 24,
    max_instances: int = 6,
    val_split: float = 0.15,
    bg_val_ratio: float = 0.08,
    probe_epochs: int = 80
) -> Tuple[bool, Optional[str], Optional[Dict]]:
    """
    è¨“ç·´ YOLO æ¨¡å‹
    
    Args:
        yolo_version: YOLO ç‰ˆæœ¬ ('yolo5', 'yolo6', 'yolo7', 'yolo8', 'yolo9', 'yolo10', 'yolo11', 'yolo12')
        model_size: æ¨¡å‹å¤§å° ('n', 's', 'm', 'l', 'x')
        images_folder: åœ–åƒè³‡æ–™å¤¾è·¯å¾‘
        labels_folder: æ¨™ç±¤è³‡æ–™å¤¾è·¯å¾‘
        output_destination: è¼¸å‡ºç›®çš„è³‡æ–™å¤¾
        epochs: è¨“ç·´è¼ªæ•¸ï¼ˆå„ªåŒ–æ¨¡å¼ä¸‹æœƒè¢«è‡ªå‹•è¨ˆç®—ï¼‰
        batch_size: æ‰¹æ¬¡å¤§å°
        imgsz: åœ–åƒå°ºå¯¸
        resume: æ˜¯å¦ç¹¼çºŒè¨“ç·´
        verbose: æ˜¯å¦è¼¸å‡ºè©³ç´°ä¿¡æ¯
        enable_optimization: æ˜¯å¦å•Ÿç”¨å„ªåŒ–æ¨¡å¼ï¼ˆæ•¸æ“šé›†æ¸…ç†ã€æ¢é‡è¨“ç·´ã€å‹•æ…‹è¶…åƒæ•¸ï¼‰
        min_w: æœ€å°æ¡†å¯¬åº¦ï¼ˆåƒç´ ï¼‰
        min_h: æœ€å°æ¡†é«˜åº¦ï¼ˆåƒç´ ï¼‰
        max_instances: æ¯å¼µåœ–åƒæœ€å¤§å¯¦ä¾‹æ•¸
        val_split: é©—è­‰é›†æ¯”ä¾‹
        bg_val_ratio: èƒŒæ™¯åœ–åƒåœ¨é©—è­‰é›†ä¸­çš„æ¯”ä¾‹
        probe_epochs: æ¢é‡è¨“ç·´è¼ªæ•¸
        
    Returns:
        (æˆåŠŸæ¨™èªŒ, æ¨¡å‹è·¯å¾‘, è¨“ç·´çµæœå­—å…¸) å…ƒçµ„
    """
    # é©—è­‰è¼¸å…¥
    if not images_folder or not os.path.exists(images_folder):
        print(f"[éŒ¯èª¤] åœ–åƒè³‡æ–™å¤¾ä¸å­˜åœ¨: {images_folder}")
        return False, None, None
    
    if not labels_folder or not os.path.exists(labels_folder):
        print(f"[éŒ¯èª¤] æ¨™ç±¤è³‡æ–™å¤¾ä¸å­˜åœ¨: {labels_folder}")
        return False, None, None
    
    if not output_destination:
        output_destination = os.path.join(os.getcwd(), 'runs', 'train')
    
    os.makedirs(output_destination, exist_ok=True)
    
    # ================= å„ªåŒ–æ¨¡å¼ï¼šæ•¸æ“šé›†æ¸…ç† =================
    if enable_optimization:
        if verbose:
            print("ğŸ§¼ [å„ªåŒ–] é–‹å§‹æ•¸æ“šé›†æ¸…ç†...")
        
        # ç¢ºå®šè¨“ç·´å’Œé©—è­‰è³‡æ–™å¤¾è·¯å¾‘
        train_images = os.path.join(images_folder, 'train') if os.path.exists(os.path.join(images_folder, 'train')) else images_folder
        train_labels = os.path.join(labels_folder, 'train') if os.path.exists(os.path.join(labels_folder, 'train')) else labels_folder
        val_images = os.path.join(images_folder, 'val') if os.path.exists(os.path.join(images_folder, 'val')) else None
        val_labels = os.path.join(labels_folder, 'val') if os.path.exists(os.path.join(labels_folder, 'val')) else None
        
        # æ•¸æ“šé›†æ¸…ç†
        remove_bad_images(train_images, train_labels, min_w=min_w, min_h=min_h, verbose=verbose)
        cap_instances(train_labels, max_inst=max_instances, verbose=verbose)
        
        # å‰µå»ºé©—è­‰é›†ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        if val_images is None or val_labels is None:
            # å˜—è©¦æ¨™æº– YOLO æ ¼å¼çµæ§‹
            dataset_root = os.path.dirname(images_folder) if os.path.dirname(images_folder) else os.path.dirname(labels_folder)
            if not dataset_root or dataset_root == images_folder or dataset_root == labels_folder:
                dataset_root = os.path.dirname(os.path.abspath(images_folder))
                if not dataset_root:
                    dataset_root = os.path.dirname(os.path.abspath(labels_folder))
            
            # ç¢ºä¿ç›®éŒ„çµæ§‹å­˜åœ¨
            val_images_dir = os.path.join(dataset_root, 'images', 'val')
            val_labels_dir = os.path.join(dataset_root, 'labels', 'val')
            os.makedirs(val_images_dir, exist_ok=True)
            os.makedirs(val_labels_dir, exist_ok=True)
            
            val_images = val_images_dir
            val_labels = val_labels_dir
        
        create_validation_set(
            train_images, train_labels,
            val_images, val_labels,
            val_split=val_split, bg_val_ratio=bg_val_ratio,
            verbose=verbose
        )
        
        # è¨ˆç®—æ•¸æ“šé›†çµ±è¨ˆ
        stats = calculate_dataset_stats(train_images, train_labels)
        if verbose:
            print(f"ğŸ“Š [å„ªåŒ–] æ•¸æ“šé›†çµ±è¨ˆ: {stats['num_imgs']} å¼µåœ–åƒ | {stats['instances']} å€‹å¯¦ä¾‹ | å¯†åº¦={stats['density']:.2f}")
        
        # æ›´æ–° images_folder å’Œ labels_folder ä»¥æŒ‡å‘æ¨™æº–çµæ§‹
        # é€™æ¨£å¾ŒçºŒçš„ data.yaml å‰µå»ºé‚è¼¯èƒ½æ­£ç¢ºè­˜åˆ¥
        if os.path.exists(os.path.join(images_folder, 'train')) or os.path.exists(os.path.join(labels_folder, 'train')):
            # å·²ç¶“æ˜¯æ¨™æº–æ ¼å¼ï¼Œä¸éœ€è¦æ›´æ–°
            pass
        else:
            # å¦‚æœä¸æ˜¯æ¨™æº–æ ¼å¼ï¼Œä½†æˆ‘å€‘å‰µå»ºäº†é©—è­‰é›†ï¼Œéœ€è¦ç¢ºä¿å¾ŒçºŒé‚è¼¯èƒ½æ­£ç¢ºè™•ç†
            # é€™è£¡æˆ‘å€‘æš«æ™‚ä¿æŒåŸæ¨£ï¼Œè®“å¾ŒçºŒé‚è¼¯è™•ç†
            pass
    
    # æ§‹å»ºæ¨¡å‹åç¨±ï¼ˆç¢ºä¿æ ¼å¼æ­£ç¢ºï¼‰
    # Ultralytics YOLO æ”¯æŒçš„æ ¼å¼ï¼š
    # - YOLOv5: yolov5n.pt, yolov5s.pt ç­‰
    # - YOLOv8+: yolo8n.pt, yolo8s.pt, yolo10n.pt, yolo10s.pt ç­‰
    # æ³¨æ„ï¼šYOLOv5 ä½¿ç”¨ 'yolov5' å‰ç¶´ï¼Œå…¶ä»–ç‰ˆæœ¬ä½¿ç”¨ 'yolo' å‰ç¶´
    
    # è™•ç† YOLOv5 çš„ç‰¹æ®Šæ ¼å¼
    if yolo_version.lower() == 'yolo5':
        model_name = f"yolov5{model_size}.pt"
    else:
        model_name = f"{yolo_version}{model_size}.pt"
    
    try:
        if verbose:
            print(f"[è¨“ç·´] é–‹å§‹è¨“ç·´ YOLO æ¨¡å‹...")
            print(f"[è¨“ç·´] æ¨¡å‹: {model_name}")
            print(f"[è¨“ç·´] åœ–åƒè³‡æ–™å¤¾: {images_folder}")
            print(f"[è¨“ç·´] æ¨™ç±¤è³‡æ–™å¤¾: {labels_folder}")
            print(f"[è¨“ç·´] è¼¸å‡ºç›®éŒ„: {output_destination}")
            print(f"[è¨“ç·´] è¼ªæ•¸: {epochs}, æ‰¹æ¬¡å¤§å°: {batch_size}, åœ–åƒå°ºå¯¸: {imgsz}")
        
        # æª¢æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆæª¢æŸ¥ç•¶å‰ç›®éŒ„å’Œ Ultralytics é»˜èªä½ç½®ï¼‰
        ultralytics_weights_dir = os.path.join(os.path.expanduser('~'), '.ultralytics', 'weights')
        possible_paths = [
            model_name,  # ç•¶å‰ç›®éŒ„
            os.path.join(ultralytics_weights_dir, model_name),  # Ultralytics é»˜èªä½ç½®
        ]
        
        model_path = None
        for path in possible_paths:
            if os.path.exists(path):
                model_path = os.path.abspath(path)
                if verbose:
                    print(f"[è¨“ç·´] æ‰¾åˆ°æœ¬åœ°æ¨¡å‹: {model_path}")
                break
        
        # è¼‰å…¥æ¨¡å‹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼ŒUltralytics æœƒè‡ªå‹•ä¸‹è¼‰ï¼‰
        # YOLO() é¡æœƒè‡ªå‹•è™•ç†ä¸‹è¼‰ï¼Œæ¨¡å‹æœƒä¿å­˜åˆ° ~/.ultralytics/weights/ ç›®éŒ„
        if not model_path:
            if verbose:
                print(f"[è¨“ç·´] æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°‡è‡ªå‹•å¾ Ultralytics ä¸‹è¼‰: {model_name}")
                print(f"[è¨“ç·´] ä¸‹è¼‰å¯èƒ½éœ€è¦ä¸€äº›æ™‚é–“ï¼Œè«‹ç¨å€™...")
                print(f"[è¨“ç·´] æ¨¡å‹å°‡ä¸‹è¼‰åˆ°: {ultralytics_weights_dir}")
        
        try:
            # ç›´æ¥ä½¿ç”¨æ¨¡å‹åç¨±ï¼ŒUltralytics æœƒè‡ªå‹•ä¸‹è¼‰ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            # é€™æ˜¯æœ€ç°¡å–®å’Œå¯é çš„æ–¹æ³•
            model = YOLO(model_name)
            
            if verbose:
                # æª¢æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è¼‰
                downloaded_path = os.path.join(ultralytics_weights_dir, model_name)
                if os.path.exists(downloaded_path):
                    print(f"[è¨“ç·´] æ¨¡å‹å·²æˆåŠŸä¸‹è¼‰åˆ°: {downloaded_path}")
                print(f"[è¨“ç·´] æ¨¡å‹è¼‰å…¥æˆåŠŸ")
        except FileNotFoundError as e:
            # å¦‚æœè‡ªå‹•ä¸‹è¼‰å¤±æ•—ï¼Œæä¾›æ›´è©³ç´°çš„éŒ¯èª¤ä¿¡æ¯
            if verbose:
                print(f"[éŒ¯èª¤] æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
                print(f"[éŒ¯èª¤] ç„¡æ³•æ‰¾åˆ°æˆ–ä¸‹è¼‰æ¨¡å‹: {model_name}")
                print(f"[æç¤º] å¯èƒ½çš„åŸå› :")
                print(f"  1. ç¶²çµ¡é€£æ¥å•é¡Œ - è«‹æª¢æŸ¥ç¶²çµ¡é€£æ¥")
                print(f"  2. æ¨¡å‹åç¨±ä¸æ­£ç¢º - è«‹ç¢ºèª YOLO ç‰ˆæœ¬å’Œæ¨¡å‹å¤§å°")
                print(f"  3. Ultralytics ç‰ˆæœ¬å•é¡Œ - è«‹æ›´æ–° ultralytics: pip install --upgrade ultralytics")
                print(f"[æç¤º] æ‰‹å‹•ä¸‹è¼‰:")
                print(f"  å¯ä»¥å¾ https://github.com/ultralytics/assets/releases ä¸‹è¼‰æ¨¡å‹æ–‡ä»¶")
                print(f"  ä¸¦æ”¾åœ¨ä»¥ä¸‹ä½ç½®ä¹‹ä¸€:")
                print(f"    - ç•¶å‰ç›®éŒ„: {os.getcwd()}")
                print(f"    - Ultralytics ç›®éŒ„: {ultralytics_weights_dir}")
            raise
        except Exception as e:
            if verbose:
                print(f"[éŒ¯èª¤] æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
                import traceback
                traceback.print_exc()
            raise
        
        # å‰µå»º data.yaml æ–‡ä»¶
        # YOLO éœ€è¦ data.yaml ä¾†æŒ‡å®šæ•¸æ“šè·¯å¾‘
        import yaml
        
        # ç¢ºä¿è·¯å¾‘ä½¿ç”¨æ­£æ–œæ ï¼ˆYOLO è¦æ±‚ï¼‰
        images_folder_normalized = images_folder.replace('\\', '/')
        labels_folder_normalized = labels_folder.replace('\\', '/')
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºæ¨™æº– YOLO æ ¼å¼ï¼ˆtrain/val/test å­è³‡æ–™å¤¾ï¼‰
        train_images = os.path.join(images_folder, 'train')
        train_labels = os.path.join(labels_folder, 'train')
        
        # ç¢ºå®šæ•¸æ“šé›†æ ¹ç›®éŒ„
        if os.path.exists(train_images) and os.path.exists(train_labels):
            # æ¨™æº–æ ¼å¼ï¼šimages/train, labels/train ç­‰
            dataset_root = os.path.dirname(images_folder)
            data_yaml_path = os.path.join(dataset_root, 'data.yaml')
            
            # æª¢æŸ¥æ˜¯å¦æœ‰é©—è­‰é›†
            val_images = os.path.join(images_folder, 'val')
            val_path = 'images/val' if os.path.exists(val_images) else 'images/train'
            
            data_config = {
                'path': dataset_root.replace('\\', '/'),
                'train': 'images/train',
                'val': val_path,  # å¿…é ˆæœ‰ valï¼Œå¦‚æœæ²’æœ‰å‰‡ä½¿ç”¨ train
            }
            
            if os.path.exists(os.path.join(images_folder, 'test')):
                data_config['test'] = 'images/test'
            
            # è¨ˆç®—é¡åˆ¥æ•¸é‡ï¼ˆå¾ labels è³‡æ–™å¤¾ä¸­çš„æ–‡ä»¶æ¨æ–·ï¼‰
            import glob
            label_files = glob.glob(os.path.join(train_labels, '*.txt'))
            if label_files:
                # è®€å–ç¬¬ä¸€å€‹æ¨™ç±¤æ–‡ä»¶ä¾†ç¢ºå®šé¡åˆ¥æ•¸é‡
                try:
                    with open(label_files[0], 'r') as f:
                        first_line = f.readline().strip()
                        if first_line:
                            # YOLO æ ¼å¼ï¼šclass_id x y w h
                            num_classes = max([int(line.split()[0]) for line in [first_line] + f.readlines() if line.strip()]) + 1
                            data_config['nc'] = num_classes
                            # å‰µå»ºé¡åˆ¥åç¨±åˆ—è¡¨
                            data_config['names'] = [f'class{i}' for i in range(num_classes)]
                except:
                    pass
            
            if 'nc' not in data_config:
                data_config['nc'] = 1  # é»˜èª1å€‹é¡åˆ¥
                data_config['names'] = ['class0']
            
        else:
            # éæ¨™æº–æ ¼å¼ï¼šç›´æ¥ä½¿ç”¨ images å’Œ labels è³‡æ–™å¤¾
            # å‰µå»ºè‡¨æ™‚ data.yaml åœ¨è¼¸å‡ºç›®éŒ„
            dataset_root = os.path.dirname(images_folder)
            data_yaml_path = os.path.join(output_destination, 'data.yaml')
            os.makedirs(output_destination, exist_ok=True)
            
            # è¨ˆç®—ç›¸å°è·¯å¾‘
            rel_images = os.path.relpath(images_folder, dataset_root).replace('\\', '/')
            rel_labels = os.path.relpath(labels_folder, dataset_root).replace('\\', '/')
            
            # YOLO è¦æ±‚å¿…é ˆæœ‰ train å’Œ valï¼Œå¦‚æœæ²’æœ‰ valï¼Œä½¿ç”¨ train ä½œç‚º val
            data_config = {
                'path': dataset_root.replace('\\', '/'),
                'train': rel_images,
                'val': rel_images,  # å¦‚æœæ²’æœ‰é©—è­‰é›†ï¼Œä½¿ç”¨è¨“ç·´é›†
            }
            
            # å˜—è©¦ç¢ºå®šé¡åˆ¥æ•¸é‡
            import glob
            label_files = glob.glob(os.path.join(labels_folder, '*.txt'))
            if label_files:
                try:
                    max_class = 0
                    for label_file in label_files[:10]:  # æª¢æŸ¥å‰10å€‹æ–‡ä»¶
                        with open(label_file, 'r') as f:
                            for line in f:
                                if line.strip():
                                    class_id = int(line.split()[0])
                                    max_class = max(max_class, class_id)
                    num_classes = max_class + 1
                    data_config['nc'] = num_classes
                    data_config['names'] = [f'class{i}' for i in range(num_classes)]
                except:
                    pass
            
            if 'nc' not in data_config:
                data_config['nc'] = 1
                data_config['names'] = ['class0']
        
        # å¯«å…¥ data.yaml æ–‡ä»¶
        with open(data_yaml_path, 'w', encoding='utf-8') as f:
            yaml.dump(data_config, f, default_flow_style=False, allow_unicode=True)
        
        if verbose:
            print(f"[è¨“ç·´] å‰µå»º data.yaml: {data_yaml_path}")
            print(f"[è¨“ç·´] æ•¸æ“šé…ç½®: {data_config}")
        
        # ================= å„ªåŒ–æ¨¡å¼ï¼šæ¢é‡è¨“ç·´å’Œå‹•æ…‹è¶…åƒæ•¸èª¿æ•´ =================
        final_epochs = epochs
        final_lr0 = 0.003
        final_mosaic = 0.6
        final_mixup = 0.05
        final_copy_paste = 0.05
        final_label_smoothing = 0.012
        stats = None
        
        if enable_optimization:
            # ç²å–æ•¸æ“šé›†çµ±è¨ˆï¼ˆå¦‚æœé‚„æ²’æœ‰ç²å–ï¼‰
            train_images = os.path.join(images_folder, 'train') if os.path.exists(os.path.join(images_folder, 'train')) else images_folder
            train_labels = os.path.join(labels_folder, 'train') if os.path.exists(os.path.join(labels_folder, 'train')) else labels_folder
            stats = calculate_dataset_stats(train_images, train_labels)
            
            # æ ¹æ“šæ•¸æ“šé›†å¤§å°é¸æ“‡æ¨¡å‹
            if stats and stats['num_imgs'] < 1500 and model_size == 'n':
                # å°æ•¸æ“šé›†ä½¿ç”¨ nano æ¨¡å‹
                pass
            elif stats and stats['num_imgs'] >= 1500 and model_size == 'n':
                # ä¸­ç­‰æ•¸æ“šé›†å»ºè­°ä½¿ç”¨ small æ¨¡å‹
                if verbose:
                    print(f"ğŸ’¡ [å„ªåŒ–] æ•¸æ“šé›†è¼ƒå¤§ï¼Œå»ºè­°ä½¿ç”¨ 's' æ¨¡å‹")
            
            # æ ¹æ“š GPU å¯ç”¨æ€§èª¿æ•´æ‰¹æ¬¡å¤§å°
            if batch_size == 16:  # ä½¿ç”¨é»˜èªå€¼æ™‚æ‰è‡ªå‹•èª¿æ•´
                batch_size = 35 if torch.cuda.is_available() else 8
                if verbose:
                    print(f"âš™ï¸ [å„ªåŒ–] è‡ªå‹•èª¿æ•´æ‰¹æ¬¡å¤§å°: {batch_size}")
            
            # æ¢é‡è¨“ç·´
            if verbose:
                print(f"ğŸ” [å„ªåŒ–] é–‹å§‹æ¢é‡è¨“ç·´ ({probe_epochs} epochs)...")
            
            probe_project = os.path.join(output_destination, 'probe_auto')
            probe_results = model.train(
                data=data_yaml_path,
                epochs=probe_epochs,
                batch=batch_size,
                imgsz=imgsz,
                optimizer='AdamW',
                lr0=0.003,
                cos_lr=True,
                mosaic=0.6,
                mixup=0.05,
                copy_paste=0.05,
                project=output_destination,
                name='probe_auto',
                verbose=verbose
            )
            
            # åˆ†ææ¢é‡è¨“ç·´çµæœ
            probe_results_csv = os.path.join(probe_project, 'results.csv')
            if os.path.exists(probe_results_csv):
                try:
                    df = pd.read_csv(probe_results_csv)
                    
                    if len(df) >= 80 and 'metrics/mAP50(B)' in df.columns:
                        # è¨ˆç®—ä¸åŒéšæ®µçš„å¢é•·é€Ÿåº¦
                        early = df["metrics/mAP50(B)"].iloc[20] - df["metrics/mAP50(B)"].iloc[0] if len(df) > 20 else 0
                        mid = df["metrics/mAP50(B)"].iloc[50] - df["metrics/mAP50(B)"].iloc[20] if len(df) > 50 else 0
                        late = df["metrics/mAP50(B)"].iloc[-1] - df["metrics/mAP50(B)"].iloc[50] if len(df) > 50 else 0
                        
                        growth_speed = early + mid * 0.7
                        saturation = max(0.0, late)
                        
                        # è‡ªå‹•é¸æ“‡æœ€çµ‚è¨“ç·´è¼ªæ•¸
                        if stats:
                            base_epochs = 150 if stats['num_imgs'] < 3000 else 180
                            density_bonus = int(40 * min(1.5, stats['density']))
                        else:
                            base_epochs = 150
                            density_bonus = 0
                        growth_bonus = int(60 * min(1.0, growth_speed))
                        
                        final_epochs = base_epochs + density_bonus + growth_bonus
                        final_epochs = max(160, min(240, final_epochs))
                        
                        # å‹•æ…‹èª¿æ•´è¶…åƒæ•¸
                        final_mosaic = 0.65 if early < 0.15 else 0.55
                        final_mixup = 0.07 if mid > 0.12 else 0.05
                        final_copy_paste = 0.05
                        final_label_smoothing = 0.02 if saturation < 0.03 else 0.012
                        final_lr0 = 0.0035 if early < 0.15 else 0.0030
                        
                        if verbose:
                            print(f"âš™ï¸ [å„ªåŒ–] è‡ªå‹•é¸æ“‡æœ€çµ‚è¨“ç·´è¼ªæ•¸: {final_epochs}")
                            print(f"âš™ï¸ [å„ªåŒ–] å‹•æ…‹è¶…åƒæ•¸: lr0={final_lr0} mosaic={final_mosaic} mixup={final_mixup} copy_paste={final_copy_paste} label_smoothing={final_label_smoothing}")
                    else:
                        if verbose:
                            print(f"âš ï¸ [å„ªåŒ–] æ¢é‡è¨“ç·´çµæœä¸å®Œæ•´ï¼Œä½¿ç”¨é»˜èªåƒæ•¸")
                except Exception as e:
                    if verbose:
                        print(f"âš ï¸ [å„ªåŒ–] åˆ†ææ¢é‡è¨“ç·´çµæœæ™‚å‡ºéŒ¯: {e}ï¼Œä½¿ç”¨é»˜èªåƒæ•¸")
            
            # å¾æ¢é‡è¨“ç·´çš„æœ€ä½³æ¨¡å‹ç¹¼çºŒ
            probe_best_model = os.path.join(probe_project, 'weights', 'best.pt')
            if os.path.exists(probe_best_model):
                model = YOLO(probe_best_model)
                if verbose:
                    print(f"ğŸ“¦ [å„ªåŒ–] å¾æ¢é‡è¨“ç·´æœ€ä½³æ¨¡å‹ç¹¼çºŒ: {probe_best_model}")
        
        # è¨“ç·´æ¨¡å‹ - ä½¿ç”¨ data.yaml çš„çµ•å°è·¯å¾‘
        train_kwargs = {
            'data': data_yaml_path,
            'epochs': final_epochs,
            'batch': batch_size,
            'imgsz': imgsz,
            'project': output_destination,
            'resume': resume,
            'verbose': verbose
        }
        
        # å¦‚æœå•Ÿç”¨å„ªåŒ–æ¨¡å¼ï¼Œæ·»åŠ å‹•æ…‹è¶…åƒæ•¸
        if enable_optimization:
            train_kwargs.update({
                'optimizer': 'AdamW',
                'lr0': final_lr0,
                'cos_lr': True,
                'mosaic': final_mosaic,
                'mixup': final_mixup,
                'copy_paste': final_copy_paste,
                'label_smoothing': final_label_smoothing,
                'patience': 45,
                'name': 'final_auto'
            })
        
        results = model.train(**train_kwargs)
        
        # ç²å–æœ€ä½³æ¨¡å‹è·¯å¾‘
        best_model_path = None
        if hasattr(results, 'save_dir'):
            best_model_path = os.path.join(str(results.save_dir), 'weights', 'best.pt')
            if not os.path.exists(best_model_path):
                # å˜—è©¦å…¶ä»–å¯èƒ½çš„è·¯å¾‘
                possible_paths = [
                    os.path.join(str(results.save_dir), 'best.pt'),
                    os.path.join(output_destination, 'weights', 'best.pt'),
                ]
                for path in possible_paths:
                    if os.path.exists(path):
                        best_model_path = path
                        break
        
        if verbose:
            print(f"[æˆåŠŸ] è¨“ç·´å®Œæˆï¼")
            if best_model_path:
                print(f"[æˆåŠŸ] æœ€ä½³æ¨¡å‹ä¿å­˜åœ¨: {best_model_path}")
        
        return True, best_model_path, {
            'save_dir': str(results.save_dir) if hasattr(results, 'save_dir') else output_destination,
            'best_model': best_model_path
        }
        
    except Exception as e:
        print(f"[éŒ¯èª¤] è¨“ç·´éç¨‹ä¸­ç™¼ç”Ÿç•°å¸¸: {e}")
        import traceback
        if verbose:
            traceback.print_exc()
        return False, None, None


# å‘½ä»¤è¡Œæ¥å£
def main():
    """å‘½ä»¤è¡Œæ¥å£"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="è¨“ç·´ YOLO æ¨¡å‹",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument("--yolo-version", type=str, default='yolo12', help="YOLO ç‰ˆæœ¬ (yolo5/yolo6/yolo7/yolo8/yolo9/yolo10/yolo11/yolo12)")
    parser.add_argument("--model-size", type=str, default='n', help="æ¨¡å‹å¤§å° (n/s/m/l/x)")
    parser.add_argument("--images", type=str, required=True, help="åœ–åƒè³‡æ–™å¤¾è·¯å¾‘")
    parser.add_argument("--labels", type=str, required=True, help="æ¨™ç±¤è³‡æ–™å¤¾è·¯å¾‘")
    parser.add_argument("--output", type=str, default='', help="è¼¸å‡ºç›®çš„è³‡æ–™å¤¾")
    parser.add_argument("--epochs", type=int, default=100, help="è¨“ç·´è¼ªæ•¸")
    parser.add_argument("--batch", type=int, default=16, help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--imgsz", type=int, default=640, help="åœ–åƒå°ºå¯¸")
    parser.add_argument("--resume", action="store_true", help="ç¹¼çºŒè¨“ç·´")
    parser.add_argument("--verbose", action="store_true", help="è¼¸å‡ºè©³ç´°ä¿¡æ¯")
    parser.add_argument("--enable-optimization", action="store_true", help="å•Ÿç”¨å„ªåŒ–æ¨¡å¼ï¼ˆæ•¸æ“šé›†æ¸…ç†ã€æ¢é‡è¨“ç·´ã€å‹•æ…‹è¶…åƒæ•¸ï¼‰")
    parser.add_argument("--min-w", type=int, default=14, help="æœ€å°æ¡†å¯¬åº¦ï¼ˆåƒç´ ï¼‰")
    parser.add_argument("--min-h", type=int, default=24, help="æœ€å°æ¡†é«˜åº¦ï¼ˆåƒç´ ï¼‰")
    parser.add_argument("--max-instances", type=int, default=6, help="æ¯å¼µåœ–åƒæœ€å¤§å¯¦ä¾‹æ•¸")
    parser.add_argument("--val-split", type=float, default=0.15, help="é©—è­‰é›†æ¯”ä¾‹")
    parser.add_argument("--bg-val-ratio", type=float, default=0.08, help="èƒŒæ™¯åœ–åƒåœ¨é©—è­‰é›†ä¸­çš„æ¯”ä¾‹")
    parser.add_argument("--probe-epochs", type=int, default=80, help="æ¢é‡è¨“ç·´è¼ªæ•¸")
    
    args = parser.parse_args()
    
    print(f"[è¨“ç·´] é–‹å§‹è¨“ç·´: {args.yolo_version}{args.model_size}")
    success, model_path, results = train_yolo_model(
        yolo_version=args.yolo_version,
        model_size=args.model_size,
        images_folder=args.images,
        labels_folder=args.labels,
        output_destination=args.output,
        epochs=args.epochs,
        batch_size=args.batch,
        imgsz=args.imgsz,
        resume=args.resume,
        verbose=args.verbose,
        enable_optimization=args.enable_optimization,
        min_w=args.min_w,
        min_h=args.min_h,
        max_instances=args.max_instances,
        val_split=args.val_split,
        bg_val_ratio=args.bg_val_ratio,
        probe_epochs=args.probe_epochs
    )
    
    if success:
        print(f"[æˆåŠŸ] è¨“ç·´å®Œæˆï¼æ¨¡å‹ä¿å­˜åœ¨: {model_path}")
        sys.exit(0)
    else:
        print("[å¤±æ•—] è¨“ç·´å¤±æ•—")
        sys.exit(1)


if __name__ == "__main__":
    main()

